{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5b37b0-9fd7-49e2-935e-29a6169a6e15",
   "metadata": {},
   "source": [
    "# Part 1. Load, Prep, Train, Register, Deploy and Scale in 50 Lines of Code\n",
    "\n",
    "In this lab you will learn how to:\n",
    "\n",
    "1. Create a session for Snowpark with Snowflake\n",
    "2. Create a DB, Warehouse and Model Registry\n",
    "3. Prep Data using the highly parallelisable vectorised UDTF functionality\n",
    "4. Build/train a regression model with Snowpark ML\n",
    "5. Register your model in the Model Registry\n",
    "6. Run the model\n",
    "\n",
    "All this in 50 lines of code (less the library imports). \n",
    "\n",
    "### Note - there are some \"TO DOs\" along the way for you to update, they are signposted with markdowns and comments, so keep your eyes open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d951e-23e8-4b74-93ff-e7e34938a4a0",
   "metadata": {},
   "source": [
    "## Prerequisites:\n",
    "In a terminal please run:\n",
    "\n",
    "conda env create -f conda_env.yml\n",
    " \n",
    "conda activate snowpark-ml-hol\n",
    "\n",
    "jupyter lab <---- this will load jupyter (you cna execute the notebook anywhere really, e.g. vscode, but jupyter is an easy option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0c57c-7a89-4a24-96aa-fb05aecb22ab",
   "metadata": {},
   "source": [
    "# 1.0 Imports\n",
    "TO DO: just run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2796f46e-5a61-47e6-84b0-a9bdeb4af2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.types import PandasDataFrameType, IntegerType, StringType, FloatType, DateType\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml.modeling.linear_model import LinearRegression\n",
    "from snowflake.ml.registry import registry\n",
    "from snowflake.ml._internal.utils import identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d4eff-d2fc-4faa-9657-d0c95223c2a1",
   "metadata": {},
   "source": [
    "# 1.1 Reading Snowflake Connection Details, create a Session\n",
    "\n",
    "TO DO: \n",
    "\n",
    "1. Create a JSON with your credentials and update the cell below\n",
    "\n",
    "{\n",
    "\"account\": \"your_account_name\", \n",
    "\"user\": \"your_user_name\",\n",
    "\"password\": \"insert_your_pwd_here\",\n",
    "\"role\": \"ACCOUNTADMIN\"\n",
    "}\n",
    "\n",
    "2. Update the location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24f6ccb-143c-40cd-b8ff-5b5b752231df",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_connection_cfg = json.loads(open(\"creds.json\").read()) # <--- 2. Update here if not in the current folder\n",
    "session = Session.builder.configs(snowflake_connection_cfg).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536caf95-150b-40d4-b60c-4a55a8c6c07a",
   "metadata": {},
   "source": [
    "# 1.2 Specify Your Database, Create a Virtual Warehouse and Load Your Data\n",
    "\n",
    "Snowflake seperates compute from storage, so we need a database AND a warehouse (compute environment) to run this stuff on.  A model registry is just a special type of database, and while you could use the same database as your data, in this case we're using a distinct database for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bedf16-8ff6-4541-8cff-b6defee453d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"CREATE OR REPLACE DATABASE MODEL_REGISTRY\").collect()\n",
    "session.sql(\"CREATE OR REPLACE SCHEMA PUBLIC\").collect()\n",
    "REGISTRY_DATABASE_NAME = \"MODEL_REGISTRY\"\n",
    "REGISTRY_SCHEMA_NAME = \"PUBLIC\"\n",
    "native_registry = registry.Registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)\n",
    "session.sql(\"CREATE OR REPLACE DATABASE HOL_DEMO\").collect()\n",
    "session.sql(\"CREATE OR REPLACE WAREHOUSE ASYNC_WH WITH WAREHOUSE_SIZE='MEDIUM' WAREHOUSE_TYPE = 'SNOWPARK-OPTIMIZED'\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856904bc-0843-4f97-b5cb-2ecb6210d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.table.Table at 0x17d1b3cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This data load is deliberately lo-fi, lots of other ways of importing data exist that have greater scale, but this compact approach is fine for this task\n",
    "session.write_pandas(pd.read_csv(\"test.csv\"), table_name='FS_DATASET', auto_create_table=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3aa05-3625-43b3-b29c-9c8edcbe9a51",
   "metadata": {},
   "source": [
    "# 1.3 Get Your Data (Prepped) With Pandas and Snowpark\n",
    "We're got time series data, and we want to munge the data into a regression friendly dataset.  Pandas is a common approach for this in data science, and while greater performance can be achieved with Snowpark native manipulations, vectorised UDTFs offer a great combination of familiarity (i.e. do the same thing you would do in pandas) and scale (parallelisation partitioned across each symbol)\n",
    "\n",
    "TO DO: just run the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cddcf88-2d39-4441-8e6d-084c4417762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = session.table(\"FS_DATASET\")\n",
    "sdf = sdf.select(F.to_date(F.col('DATE')).as_('DATE'), \"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\", \"SYMBOL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a4edbe-cef2-4cf1-a56a-e2b4218b8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_Prep:\n",
    "    def end_partition(self, df):\n",
    "        df.columns = ['_DATE', \"_OPEN\", \"_HIGH\", \"_LOW\", \"_CLOSE\", \"_SYMBOL\"]\n",
    "        for i in range(1,6):\n",
    "            df[\"_CLOSE-\" + str(i)] = df[\"_CLOSE\"].shift(i).bfill()\n",
    "        yield df\n",
    "\n",
    "ML_Prep.end_partition._sf_vectorized_input = pd.DataFrame\n",
    "\n",
    "ml_prep_udtf = session.udtf.register(\n",
    "    ML_Prep, # the class\n",
    "    name=\"ml_prep_udtf\",\n",
    "    input_types=[PandasDataFrameType([DateType(), FloatType(), FloatType(), FloatType(), FloatType(), StringType()])], \n",
    "    output_schema=PandasDataFrameType([DateType(), FloatType(), FloatType(), FloatType(), FloatType(), StringType(),FloatType(),FloatType(),FloatType(),FloatType(),FloatType(),FloatType()],\n",
    "                                      ['DATE', \"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\", \"SYMBOL\", \"CLOSE_M1\", \"CLOSE_M2\", \"CLOSE_M3\", \"CLOSE_M4\", \"CLOSE_M5\"]),\n",
    "    packages=[\"snowflake-snowpark-python\", 'pandas'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630b8ea6-0e46-4be2-874b-834daa07be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_prepped = sdf.select(ml_prep_udtf(*[\"DATE\", \"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\", \"SYMBOL\"]).over(partition_by=['SYMBOL']))\n",
    "sdf_prepped.limit(10).to_pandas()\n",
    "sdf_prepped.write.save_as_table(\"ML_PREPPED\", mode=\"overwrite\")\n",
    "sdf[['SYMBOL']].distinct().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156f278-a61c-4099-83ea-8e3795778e69",
   "metadata": {},
   "source": [
    "# 1.4.1 Choose Your Symbol, Train/Test Split and Model\n",
    "\n",
    "We've got our data ready, but we need to make a few selections before we build our models\n",
    "\n",
    "TO DO:\n",
    "1. Choose the Symbol you want to build a model for\n",
    "2. Pick the date range for your train/test split\n",
    "3. Pick a regression model you want type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f836f8-8c4b-4756-96a9-531c8d5ce1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_prepped_filt = sdf_prepped.filter((F.col(\"SYMBOL\") == \"\")) # <---- update 1.\n",
    "sdf_filt_train, sdf_filt_test = sdf_prepped_filt.filter((F.col(\"DATE\") <= '')), sdf_prepped_filt.filter((F.col(\"DATE\") > '')) # <---- update 2.\n",
    "regressor = # <---- update 3. hint one look at our imports cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6bd7a0-8c07-4a1e-bd99-79feb745e9d1",
   "metadata": {},
   "source": [
    "# 1.4.2 Train Your Model\n",
    "\n",
    "Our model is almost ready to be trained, but we need to choose our inputs, targets, and outputs.  We could go off piste and alter model (hyper)parameters here too (https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/api/modeling/snowflake.ml.modeling.linear_model.LinearRegression)\n",
    "\n",
    "TO DO:\n",
    "1. Select your input columns\n",
    "2. Select your target(label) column\n",
    "3. Choose your output column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603873ea-5bb6-4eee-8121-07780e5b2a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.modeling.linear_model.linear_regression.LinearRegression at 0x17d760550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = regressor(input_cols=[], # <---- update 1.\n",
    "                         label_cols=[], # <---- update 2.\n",
    "                         output_cols=[]) # <---- update 3.\n",
    "regressor.fit(sdf_prepped_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863df7a-2670-4a10-82a6-dc99a5e17e4c",
   "metadata": {},
   "source": [
    "# 1.5 Register Your Model\n",
    "\n",
    "Let's assume we love the first model, it's time to register it....\n",
    "\n",
    "TO DO:\n",
    "1. Choose a  model name\n",
    "2. Choose a model version (note the combo of name and version needs to be unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7cae620-c9c5-4cbd-a1cd-be3af51ca230",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = # <---- update 1. use a string like \"REGRESSION_MODEL\"\n",
    "MODEL_VERSION = # <---- update 2. use a string like \"v1\"\n",
    "\n",
    "model = native_registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    version_name=MODEL_VERSION,\n",
    "    model=regressor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a0dd1-6bc6-4ef4-96e2-4e5da582b247",
   "metadata": {},
   "source": [
    "# 1.6 Run Your Model\n",
    "\n",
    "We're at the finish line!\n",
    "\n",
    "TO DO: just run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d0c6a-dc4d-4665-94f8-34d7275351dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(sdf_filt_test, function_name=\"predict\").limit(20).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c115265-fc9c-40a5-bc2b-b4995269befc",
   "metadata": {},
   "source": [
    "## Make sure you run this last line - it's needed for the Part 2. and 3. of the Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49d682-5551-494c-9ea7-c59caac54f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = native_registry.get_model(MODEL_NAME).version(MODEL_VERSION)\n",
    "model_.run(sdf_filt_test, function_name=\"predict\").write.save_as_table(\"ML_PREDICT\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
